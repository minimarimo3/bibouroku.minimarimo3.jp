import subprocess
import json
import re
import os
import shutil
import datetime
from xml.sax.saxutils import escape

# --- è¨­å®š ---
ROOT_DIR = "."
POSTS_FILE = "posts.typ"
METADATA_LABEL = "<post-list>"
BASE_URL = "https://bibouroku.minimarimo3.jp"  # ã‚ãªãŸã®ãƒ‰ãƒ¡ã‚¤ãƒ³
STYLE_CSS = "style.css"  # å…±é€šCSSã®ãƒ•ã‚¡ã‚¤ãƒ«å
SCRIPT_JS = "script.js"  # å…±é€šJSã®ãƒ•ã‚¡ã‚¤ãƒ«å

# ã‚³ãƒ”ãƒ¼ã™ã‚‹é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ï¼ˆå¿…è¦ã«å¿œã˜ã¦è¿½åŠ ï¼‰
STATIC_EXTENSIONS = {".png", ".jpg", ".jpeg", ".gif", ".svg", ".webp", ".pdf", ".js"}

def build():
    print("ğŸš€ ãƒ“ãƒ«ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™...")
    
    # publicãƒ•ã‚©ãƒ«ãƒ€ã®ãƒªã‚»ãƒƒãƒˆï¼ˆå¿…è¦ãªã‚‰ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã™ï¼‰
    if os.path.exists("public"):
        shutil.rmtree("public")
    os.makedirs("public", exist_ok=True)

    # 1. è¨˜äº‹ãƒªã‚¹ãƒˆã®å–å¾—
    try:
        result = subprocess.run(
            ["typst", "query", "--field", "value", POSTS_FILE, METADATA_LABEL],
            capture_output=True,
            text=True,
            check=True,
            encoding="utf-8"
        )
        posts_dict = json.loads(result.stdout)[0]
        print(f"ğŸ“„ {len(posts_dict)} ä»¶ã®è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚\n")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: è¨˜äº‹ãƒªã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n{e}")
        return

    # è¨˜äº‹ãƒªã‚¹ãƒˆã‚’æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
    # Typstã®datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯è¾æ›¸ã¨ã—ã¦æ¸¡ã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã®ã§ãƒ‘ãƒ¼ã‚¹ã™ã‚‹
    sorted_posts = []
    for dir_path, meta in posts_dict.items():
        meta["dir_path"] = dir_path
        # æ—¥ä»˜ã®ãƒ‘ãƒ¼ã‚¹å‡¦ç†
        create_date = meta.get("create")
        # æ–‡å­—åˆ—ã®å ´åˆ: "datetime(year: 2025, month: 12, day: 14)" å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
        # æ­£è¦è¡¨ç¾ã§ year, month, day ã‚’æŠ½å‡º
        match = re.search(r"year:\s*(\d+),\s*month:\s*(\d+),\s*day:\s*(\d+)", create_date)
        if match:
            dt = datetime.datetime(
                int(match.group(1)),
                int(match.group(2)),
                int(match.group(3))
            )
        meta["dt"] = dt
        sorted_posts.append(meta)

    sorted_posts.sort(key=lambda x: x["dt"], reverse=True)


    # 2. å„è¨˜äº‹ã®ãƒ“ãƒ«ãƒ‰ & é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼
    for post in sorted_posts:
        dir_path = post["dir_path"]
        title = post.get("title", "ç„¡é¡Œ")
        
        # ãƒ‘ã‚¹è¨­å®š
        input_dir = os.path.join(ROOT_DIR, dir_path)
        input_file = os.path.join(input_dir, "index.typ")
        output_dir = os.path.join("public", dir_path)
        output_file = os.path.join(output_dir, "index.html")
        
        if not os.path.exists(input_file):
            print(f"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ ({input_file})")
            continue

        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ”¨ Compiling: {title}")

        # (A) Typstã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        try:
            subprocess.run([
                "typst", "compile", "--features", "html", "--format", "html",
                "--root", ROOT_DIR, input_file, output_file
            ], check=True)
        except subprocess.CalledProcessError:
            print(f"âŒ ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¤±æ•—: {title}")
            continue

        # (B) é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç”»åƒãªã©ï¼‰ã®ã‚³ãƒ”ãƒ¼
        # è¨˜äº‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èµ°æŸ»
        for filename in os.listdir(input_dir):
            base, ext = os.path.splitext(filename)
            if ext.lower() in STATIC_EXTENSIONS:
                src = os.path.join(input_dir, filename)
                dst = os.path.join(output_dir, filename)
                shutil.copy2(src, dst)
                print(f"  Example: {filename} ã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ")

    # 3. å…±é€šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ“ãƒ«ãƒ‰ãƒ»ã‚³ãƒ”ãƒ¼
    print("\nğŸ  Building static pages...")
    
    # ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸
    try:
        subprocess.run(["typst", "compile", "--features", "html", "--format", "html", "--root", ROOT_DIR, "index.typ", "public/index.html"], check=True)
    except: print("âŒ ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¤±æ•—")

    # 404ãƒšãƒ¼ã‚¸
    if os.path.exists("404.typ"):
        try:
            subprocess.run(["typst", "compile", "--features", "html", "--format", "html", "--root", ROOT_DIR, "404.typ", "public/404.html"], check=True)
            print("âœ… 404ãƒšãƒ¼ã‚¸ç”Ÿæˆå®Œäº†")
        except: print("âŒ 404ãƒšãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¤±æ•—")

    # CSSã‚³ãƒ”ãƒ¼
    if os.path.exists(STYLE_CSS):
        shutil.copy2(STYLE_CSS, "public/style.css")
        print("âœ… CSSã‚³ãƒ”ãƒ¼å®Œäº†")
    else:
        print("âš ï¸ style.css ãŒãƒ«ãƒ¼ãƒˆã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆpublic/style.cssã¨ã—ã¦æ—¢ã«å­˜åœ¨ã™ã‚‹ãªã‚‰OKï¼‰")

    # JSã‚³ãƒ”ãƒ¼
    if os.path.exists(SCRIPT_JS):
        shutil.copy2(SCRIPT_JS, "public/script.js")
        print("âœ… JSã‚³ãƒ”ãƒ¼å®Œäº†")
    else:
        print("âš ï¸ script.js ãŒãƒ«ãƒ¼ãƒˆã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆpublic/script.jsã¨ã—ã¦æ—¢ã«å­˜åœ¨ã™ã‚‹ãªã‚‰OKï¼‰")


    # 4. RSSãƒ•ã‚£ãƒ¼ãƒ‰ & ã‚µã‚¤ãƒˆãƒãƒƒãƒ—ç”Ÿæˆ
    print("\nğŸ“¡ Generating RSS & Sitemap...")
    generate_rss(sorted_posts)
    generate_sitemap(sorted_posts)
    print("âœ… ãƒ“ãƒ«ãƒ‰å®Œäº†ï¼")


def generate_rss(posts):
    rss_path = os.path.join("public", "feed.xml")
    now = datetime.datetime.now(datetime.timezone.utc).strftime("%a, %d %b %Y %H:%M:%S GMT")
    
    xml = f"""<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
  <title>Bibouroku</title>
  <link>{BASE_URL}</link>
  <description>Typstã§ä½œã‚‰ã‚ŒãŸå‚™å¿˜éŒ²ãƒ–ãƒ­ã‚°</description>
  <lastBuildDate>{now}</lastBuildDate>
"""
    for post in posts:
        title = escape(post.get("title", "No Title"))
        link = f"{BASE_URL}/{post['dir_path']}/" # ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚ã‚Š
        desc = escape(post.get("description", ""))
        # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (RFC 822)
        pub_date = post["dt"].strftime("%a, %d %b %Y 00:00:00 GMT")
        
        xml += f"""  <item>
    <title>{title}</title>
    <link>{link}</link>
    <description>{desc}</description>
    <pubDate>{pub_date}</pubDate>
  </item>
"""
    xml += "</channel>\n</rss>"
    
    with open(rss_path, "w", encoding="utf-8") as f:
        f.write(xml)

def generate_sitemap(posts):
    sitemap_path = os.path.join("public", "sitemap.xml")
    
    xml = f"""<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url>
    <loc>{BASE_URL}/</loc>
    <priority>1.0</priority>
  </url>
"""
    for post in posts:
        link = f"{BASE_URL}/{post['dir_path']}/"
        last_mod = post["dt"].strftime("%Y-%m-%d")
        
        xml += f"""  <url>
    <loc>{link}</loc>
    <lastmod>{last_mod}</lastmod>
    <priority>0.8</priority>
  </url>
"""
    xml += "</urlset>"
    
    with open(sitemap_path, "w", encoding="utf-8") as f:
        f.write(xml)

if __name__ == "__main__":
    build()
